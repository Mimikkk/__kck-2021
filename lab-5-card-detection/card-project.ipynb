{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports used in the project."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, astuple\n",
    "import os\n",
    "import pathlib\n",
    "import base64\n",
    "from typing import *\n",
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import io\n",
    "import keras\n",
    "from PIL import Image\n",
    "import xmltodict\n",
    "import pylab as pl"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Sets.\n",
    "- first set : [Playing Cards Labelized Dataset](https://www.kaggle.com/hugopaigneau/playing-cards-dataset).\n",
    "- second set : [Playing Cards](https://www.kaggle.com/vdntdesai11/playing-cards).\n",
    "\n",
    "#### Parsing Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "Paths: Dict[str, str] = {\n",
    "  'resources': 'resources/',\n",
    "  'yolo': 'resources/cards/yolo-labeled/',\n",
    "  'xml': 'resources/cards/xml-labeled/',\n",
    "  'record': 'resources/cards/combined_record'\n",
    "}\n",
    "\n",
    "class FileReader(object):\n",
    "  @classmethod\n",
    "  def read(cls, filepath: str) -> bytes:\n",
    "    with tf.io.gfile.GFile(filepath, 'rb') as file: return file.read()\n",
    "class ImageReader(FileReader):\n",
    "  @classmethod\n",
    "  def encoded_file(cls, imagepath: str) -> bytes:\n",
    "    raw = super().read(imagepath)\n",
    "    return base64.b85encode(raw).decode('utf-8')\n",
    "\n",
    "  @classmethod\n",
    "  def encoded(cls, image: Image.Image) -> bytes:\n",
    "    with io.BytesIO() as buffer:\n",
    "      image.save(buffer, image.format)\n",
    "      return base64.b85encode(buffer.getvalue())\n",
    "\n",
    "  @classmethod\n",
    "  def decoded(cls, imageraw: str) -> Image.Image:\n",
    "    return Image.open(io.BytesIO(base64.b85decode(imageraw)))\n",
    "\n",
    "  @classmethod\n",
    "  def read(cls, imagepath: str) -> Image.Image:\n",
    "    return Image.open(io.BytesIO(super().read(imagepath)))\n",
    "\n",
    "  @classmethod\n",
    "  def read_resized(cls, imagepath: str, size: Tuple[int, int] = (400, 400)) -> Image.Image:\n",
    "    image = cls.read(imagepath)\n",
    "    new = image\n",
    "    new = new.resize(size, Image.ANTIALIAS)\n",
    "    new.format = image.format\n",
    "    return new\n",
    "\n",
    "class FeatureProvider(object):\n",
    "  @classmethod\n",
    "  def i64(cls, value) -> tf.train.Feature:\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "  @classmethod\n",
    "  def i64_list(cls, value) -> tf.train.Feature:\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "  @classmethod\n",
    "  def u8(cls, value) -> tf.train.Feature:\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "  @classmethod\n",
    "  def u8_list(cls, value) -> tf.train.Feature:\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "  @classmethod\n",
    "  def f32(cls, value) -> tf.train.Feature:\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "  @classmethod\n",
    "  def f32_list(cls, value) -> tf.train.Feature:\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "class RecordProvider(FeatureProvider):\n",
    "  @classmethod\n",
    "  def record(cls, features: Dict[str, tf.train.Feature]) -> tf.train.Example:\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "class FeatureWriter(object):\n",
    "  @staticmethod\n",
    "  def write(records: Iterable[tf.train.Example], target: str):\n",
    "    with tf.io.TFRecordWriter(f\"{target}.record\") as writer:\n",
    "      for record in records: writer.write(record.SerializeToString())\n",
    "\n",
    "  @staticmethod\n",
    "  def combine_write(record_iterators: Iterable[Iterable[tf.train.Example]], target: str, total: int = None):\n",
    "    with tf.io.TFRecordWriter(f\"{target}.record\") as writer:\n",
    "      for (index, record) in enumerate((record for iterator in record_iterators for record in iterator), start=1):\n",
    "        if (index % 100) == 0: print(f\"{index}{f'/{total}' if total else ''} records written.\")\n",
    "        writer.write(record.SerializeToString())\n",
    "\n",
    "class FeatureReader(object):\n",
    "  @classmethod\n",
    "  def read(cls, source: str) -> tf.data.TFRecordDataset:\n",
    "    return tf.data.TFRecordDataset(f\"{source}.record\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensorflow Record preparation\n",
    "\n",
    "### Parsing records from 'Playing Cards Labelized Dataset' dataset\n",
    "\n",
    "#### Parse Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "Classes: Dict[str, str] = {\n",
    "  'As': 1, 'Ac': 13, 'Ad': 26, 'Ah': 39,\n",
    "  'Ks': 2, 'Kc': 14, 'Kd': 27, 'Kh': 40,\n",
    "  'Qs': 3, 'Qc': 15, 'Qd': 28, 'Qh': 41,\n",
    "  'Js': 4, 'Jc': 16, 'Jd': 29, 'Jh': 42,\n",
    "  '10s': 5, '10c': 17, '10d': 30, '10h': 43,\n",
    "  '9s': 6, '9c': 18, '9d': 31, '9h': 44,\n",
    "  '8s': 7, '8c': 19, '8d': 32, '8h': 45,\n",
    "  '7s': 8, '7c': 20, '7d': 33, '7h': 46,\n",
    "  '6s': 9, '6c': 21, '6d': 34, '6h': 47,\n",
    "  '5s': 10, '5c': 22, '5d': 35, '5h': 48,\n",
    "  '4s': 11, '4c': 23, '4d': 36, '4h': 49,\n",
    "  '3s': 12, '3c': 24, '3d': 37, '3h': 50,\n",
    "  '2s': 25, '2c': 38, '2d': 51, '2h': 52,\n",
    "}\n",
    "\n",
    "Xml = Dict[str, Union['Xml', str]]\n",
    "class XmlReader(FileReader):\n",
    "  @classmethod\n",
    "  def read(cls, xmlpath: str) -> Xml:\n",
    "    return xmltodict.parse(super().read(xmlpath))\n",
    "class XMlRecordProvider(RecordProvider):\n",
    "  @classmethod\n",
    "  def to_record(cls, image: Image.Image, xml: Xml) -> tf.train.Example:\n",
    "    return cls.record(cls._parse(image, xml))\n",
    "\n",
    "  @classmethod\n",
    "  def _parse(cls, image: Image.Image, xml: Xml):\n",
    "    filename = xml['annotation']['filename']\n",
    "    (width, height) = map(int, (xml['annotation']['size']['width'], xml['annotation']['size']['height']))\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for card in xml['annotation']['object']:\n",
    "      xmins.append(int(card['bndbox']['xmin']) / width)\n",
    "      xmaxs.append(int(card['bndbox']['xmax']) / width)\n",
    "      ymins.append(int(card['bndbox']['ymin']) / height)\n",
    "      ymaxs.append(int(card['bndbox']['ymax']) / height)\n",
    "      texts.append(card['name'].encode('utf8'))\n",
    "      labels.append(Classes[card['name']])\n",
    "\n",
    "    return {\n",
    "      'name': cls.u8(filename.encode('utf8')),\n",
    "      'encoded': cls.u8(ImageReader.encoded(image)),\n",
    "      'format': cls.u8(image.format.encode('utf8')),\n",
    "      'height': cls.i64(image.height),\n",
    "      'width': cls.i64(image.width),\n",
    "      'cards/bbox/xmin': cls.f32_list(xmins),\n",
    "      'cards/bbox/xmax': cls.f32_list(xmaxs),\n",
    "      'cards/bbox/ymin': cls.f32_list(ymins),\n",
    "      'cards/bbox/ymax': cls.f32_list(ymaxs),\n",
    "      'cards/class/text': cls.u8_list(texts),\n",
    "      'cards/class/label': cls.i64_list(labels),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Parsing process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def xml_pathfinder(extension: str) -> pathlib.Path:\n",
    "  return pathlib.Path(Paths['xml']).glob(f\"*.{extension}\")\n",
    "def xml_record(data: Tuple[Image.Image, Xml]) -> tf.train.Example:\n",
    "  return XMlRecordProvider.to_record(*data)\n",
    "def find_xml_record_count():\n",
    "  return len(list(xml_pathfinder('jpg')))\n",
    "\n",
    "images = map(ImageReader.read_resized, xml_pathfinder('jpg'))\n",
    "xmls = map(XmlReader.read, xml_pathfinder('xml'))\n",
    "\n",
    "xml_count = find_xml_record_count()\n",
    "xml_records = map(xml_record, zip(images, xmls))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parsing records from 'Playing Cards' dataset\n",
    "\n",
    "#### Parse Classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Yolo(object):\n",
    "  classname: str\n",
    "  x_center: float\n",
    "  y_center: float\n",
    "  width: float\n",
    "  height: float\n",
    "\n",
    "  @classmethod\n",
    "  def from_bbox(cls, bbox: 'BBox') -> 'Yolo':\n",
    "    (classname, xmin, xmax, ymin, ymax) = astuple(bbox)\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x = (xmax + xmin) / 2.0\n",
    "    y = (ymax + ymin) / 2.0\n",
    "    return cls(classname, x, y, w, h)\n",
    "@dataclass\n",
    "class BBox(object):\n",
    "  classname: str\n",
    "  xmin: float\n",
    "  xmax: float\n",
    "  ymin: float\n",
    "  ymax: float\n",
    "\n",
    "  @classmethod\n",
    "  def from_yolo(cls, yolo: Yolo) -> 'BBox':\n",
    "    (classname, x_center, y_center, width, height) = astuple(yolo)\n",
    "    xmax = width / 2 + x_center\n",
    "    xmin = 2 * x_center - xmax\n",
    "\n",
    "    ymax = height / 2 + y_center\n",
    "    ymin = 2 * y_center - ymax\n",
    "    return cls(classname, xmin, xmax, ymin, ymax)\n",
    "\n",
    "class YoloReader(FileReader):\n",
    "  classnames: List[str] = [\n",
    "    '2c', '3c', '4c', '5c',\n",
    "    '6c', '7c', '8c', '9c',\n",
    "    '10c', 'Ac', 'Jc', 'Kc',\n",
    "    'Qc',\n",
    "    '2d', '3d', '4d', '5d',\n",
    "    '6d', '7d', '8d', '9d',\n",
    "    '10d', 'Ad', 'Jd', 'Kd',\n",
    "    'Qd',\n",
    "    '2h', '3h', '4h', '5h',\n",
    "    '6h', '7h', '8h', '9h',\n",
    "    '10h', 'Ah', 'Jh', 'Kh',\n",
    "    'Qh',\n",
    "    'As', '2s', '3s', '4s',\n",
    "    '5s', '6s', '7s', '8s',\n",
    "    '9s', '10s', 'Js', 'Ks',\n",
    "    'Qs'\n",
    "  ]\n",
    "\n",
    "  @classmethod\n",
    "  def read(cls, yolopath: str) -> Yolo:\n",
    "    yolos = []\n",
    "    for yolo_card in super().read(yolopath).decode('utf-8').splitlines():\n",
    "      (index, *args) = map(float, yolo_card.split())\n",
    "      yolos.append(Yolo(cls.classnames[int(index)], *args))\n",
    "    return yolos\n",
    "\n",
    "class YoloRecordProvider(RecordProvider):\n",
    "  @classmethod\n",
    "  def to_record(cls, image: Image.Image, yolos: List[Yolo]) -> tf.train.Example:\n",
    "    return cls.record(cls._parse(image, yolos))\n",
    "\n",
    "  @classmethod\n",
    "  def _parse(cls, image: Image.Image, yolos: List[Yolo]):\n",
    "    (xmins, xmaxs, ymins, ymaxs) = ([], [], [], [])\n",
    "    (texts, labels) = ([], [])\n",
    "\n",
    "    for (classname, xmin, xmax, ymin, ymax) in map(astuple, map(BBox.from_yolo, yolos)):\n",
    "      texts.append(classname.encode('utf8'))\n",
    "      labels.append(Classes[classname])\n",
    "      xmins.append(xmin)\n",
    "      xmaxs.append(xmax)\n",
    "      ymins.append(ymin)\n",
    "      ymaxs.append(ymax)\n",
    "\n",
    "    return {\n",
    "      'name': cls.u8('filename'.encode('utf8')),\n",
    "      'encoded': cls.u8(ImageReader.encoded(image)),\n",
    "      'format': cls.u8(image.format.encode('utf8')),\n",
    "      'height': cls.i64(image.height),\n",
    "      'width': cls.i64(image.width),\n",
    "      'cards/bbox/xmin': cls.f32_list(xmins),\n",
    "      'cards/bbox/xmax': cls.f32_list(xmaxs),\n",
    "      'cards/bbox/ymin': cls.f32_list(ymins),\n",
    "      'cards/bbox/ymax': cls.f32_list(ymaxs),\n",
    "      'cards/class/text': cls.u8_list(texts),\n",
    "      'cards/class/label': cls.i64_list(labels),\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Parsing Process"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def yolo_pathfinder(extension: str) -> pathlib.Path:\n",
    "  return pathlib.Path(Paths['yolo']).glob(f\"*.{extension}\")\n",
    "def yolo_record(data: Tuple[Image.Image, Any]) -> tf.train.Example:\n",
    "  return YoloRecordProvider.to_record(*data)\n",
    "def find_yolo_record_count():\n",
    "  return len(list(yolo_pathfinder('jpg')))\n",
    "\n",
    "images = map(ImageReader.read_resized, yolo_pathfinder('jpg'))\n",
    "yolos = map(YoloReader.read, yolo_pathfinder('txt'))\n",
    "\n",
    "yolo_count = find_yolo_record_count()\n",
    "yolo_records = map(yolo_record, zip(images, yolos))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 110,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving parsed records into record TensorFlow file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started writing record...\n"
     ]
    }
   ],
   "source": [
    "print(\"Started writing record...\")\n",
    "FeatureWriter.combine_write((xml_records, yolo_records), Paths['record'], total=xml_count + yolo_count)\n",
    "print(\"Finished writing record...\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def draw_bbox(image: Image.Image, record):\n",
    "  feature = lambda name: record.features.feature[name].float_list.value\n",
    "\n",
    "  image = ImageReader.decoded(record.features.feature['encoded'].bytes_list.value[0])\n",
    "  open_cv_image = np.array(image)\n",
    "  (width, height, _) = open_cv_image.shape\n",
    "  for (classname, xmin, xmax, ymin, ymax) in zip(record.features.feature['cards/class/text'].bytes_list.value,\n",
    "                                                 *map(feature, (\n",
    "                                                     'cards/bbox/xmin', 'cards/bbox/xmax', 'cards/bbox/ymin',\n",
    "                                                     'cards/bbox/ymax'))):\n",
    "    (xmin, xmax, ymin, ymax) = map(int, (xmin * width, xmax * width, ymin * height, ymax * height))\n",
    "    cv2.rectangle(open_cv_image, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
    "  pl.plt.imshow(open_cv_image)\n",
    "# print(f\"TensorFlow version: {tf.__version__}\")\n",
    "# print(f\"|> Training set row example <|\")\n",
    "# print(dfs['train'].head())\n",
    "#\n",
    "# print(f\"|> Test set row example <|\")\n",
    "# print(dfs['test'].head())\n",
    "# print(len(dfs['test']))\n",
    "#\n",
    "# print(f\"|> Dataset classes <|\")\n",
    "# print(dfs['train']['class'].unique())\n",
    "# print(f\"len(dfs['train'])\")\n",
    "#\n",
    "# print(\"|> Example paths <|\")\n",
    "# for cardpath in cardpaths.take(5): print(cardpath.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Augmenting.\n",
    "\n",
    "### Read saved data from record"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = FeatureReader.read(Paths['record'])\n",
    "for data in test_data.take(2):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(data.numpy())\n",
    "  bytes_ = example.features.feature['encoded'].bytes_list.value[0]\n",
    "  image = ImageReader.decoded(bytes_)\n",
    "  image.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading augmented."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model: keras.Sequential = keras.Sequential([\n",
    "  tf.keras.layers.Rescaling(1. / 255),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(len(Classes))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compiling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(\n",
    "  dfs['train']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validating."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wniosking."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}